{
    "base_model": "EleutherAI/gpt-neo-125m",
    "dataset_member": "the_pile",
    "dataset_nonmember": "the_pile",
    "min_words": 100,
    "max_words": 200,
    "max_tokens": 512,
    "max_data": 100000,
    "output_name": "unified_mia",
    "specific_source": "Github",
    "n_samples": 1000,
    "blackbox_attacks": ["ref"],
    "ref_config": {
        "models": [
            "stabilityai/stablelm-base-alpha-3b-v2",
            "EleutherAI/gpt-neo-1.3B",
            "EleutherAI/pythia-1.4b-deduped",
            "EleutherAI/pythia-1.4b",
            "facebook/opt-1.3B",
            "distilgpt2"
        ]
    },
    "neighborhood_config": {
        "model": "bert",
        "n_perturbation_list": [
            25
        ],
        "pct_words_masked": 0.3,
        "span_length": 2,
        "dump_cache": false,
        "load_from_cache": true
    },
    "env_config": {
        "results": "results_new",
        "device_map": "balanced_low_0"
    },
    "dump_cache": false,
    "load_from_cache": true
}